{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe4360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================================================================================================\n",
      "ACCURACY ANALYSIS: SMALL vs MIXED DATASETS\n",
      "====================================================================================================================================================================================\n",
      "\n",
      "Configuration Legend:\n",
      "  - Prompts: Few-shot or Zero-shot\n",
      "  - Pipeline: Baseline | EM-RAG | EM-KGRAG\n",
      "  - Hop Type: One-hop | Multi-hop\n",
      "  - Top-K: k=1 | k=3 (number of evidence paths retrieved)\n",
      "  - Evidence Format: - (baseline) | Text (RAG) | Python-code | JSON\n",
      "  - Accuracy: Excluding abstains\n",
      "  - Coverage: Percentage of non-abstain predictions\n",
      "\n",
      "Processing files...\n",
      "Warning: mixed_few_baseline.csv not found\n",
      "Warning: mixed_few_multi_hop_1.csv not found\n",
      "Warning: mixed_few_multi_hop_3_python.csv not found\n",
      "Warning: mixed_few_multi_hop_3.csv not found\n",
      "Warning: mixed_few_one_hop_1.csv not found\n",
      "Warning: mixed_few_one_hop_3_python.csv not found\n",
      "Warning: mixed_few_one_hop_3.csv not found\n",
      "Warning: mixed_few_rag.csv not found\n",
      "Warning: mixed_zero_baseline.csv not found\n",
      "Warning: mixed_zero_multi_hop_1.csv not found\n",
      "Warning: mixed_zero_multi_hop_3_python.csv not found\n",
      "Warning: mixed_zero_multi_hop_3.csv not found\n",
      "Warning: mixed_zero_one_hop_1.csv not found\n",
      "Warning: mixed_zero_one_hop_3_python.csv not found\n",
      "Warning: mixed_zero_one_hop_3.csv not found\n",
      "Warning: mixed_zero_rag.csv not found\n",
      "\n",
      "====================================================================================================================================================================================\n",
      "SIDE-BY-SIDE COMPARISON: SMALL vs MIXED DATASETS\n",
      "====================================================================================================================================================================================\n",
      "\n",
      "Prompts      Pipeline     Hop Type     Top-K    Evidence        Acc_small    Cov_small    Abs_small    Acc_mixed    Cov_mixed    Abs_mixed   \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Few-shot     Baseline     Unknown      Unknown  -               100.00%      31.37%       35           N/A          N/A          N/A         \n",
      "Few-shot     EM-KGRAG     Multi-hop    k=1      JSON            88.57%       68.63%       16           N/A          N/A          N/A         \n",
      "Few-shot     EM-KGRAG     Multi-hop    k=3      JSON            76.92%       76.47%       12           N/A          N/A          N/A         \n",
      "Few-shot     EM-KGRAG     One-hop      k=1      JSON            86.67%       58.82%       21           N/A          N/A          N/A         \n",
      "Few-shot     EM-KGRAG     One-hop      k=3      JSON            89.74%       76.47%       12           N/A          N/A          N/A         \n",
      "Few-shot     EM-KGRAG     Multi-hop    k=3      Python-code     89.19%       72.55%       14           N/A          N/A          N/A         \n",
      "Few-shot     EM-KGRAG     One-hop      k=3      Python-code     89.19%       72.55%       14           N/A          N/A          N/A         \n",
      "Few-shot     EM-RAG       Unknown      Unknown  Text            77.14%       68.63%       16           N/A          N/A          N/A         \n",
      "Zero-shot    Baseline     Unknown      Unknown  -               93.33%       29.41%       36           N/A          N/A          N/A         \n",
      "Zero-shot    EM-KGRAG     Multi-hop    k=1      JSON            96.55%       56.86%       22           N/A          N/A          N/A         \n",
      "Zero-shot    EM-KGRAG     Multi-hop    k=3      JSON            89.66%       56.86%       22           N/A          N/A          N/A         \n",
      "Zero-shot    EM-KGRAG     One-hop      k=1      JSON            96.30%       52.94%       24           N/A          N/A          N/A         \n",
      "Zero-shot    EM-KGRAG     One-hop      k=3      JSON            93.55%       60.78%       20           N/A          N/A          N/A         \n",
      "Zero-shot    EM-KGRAG     Multi-hop    k=3      Python-code     88.00%       49.02%       26           N/A          N/A          N/A         \n",
      "Zero-shot    EM-KGRAG     One-hop      k=3      Python-code     88.46%       50.98%       25           N/A          N/A          N/A         \n",
      "Zero-shot    EM-RAG       Unknown      Unknown  Text            82.14%       54.90%       23           N/A          N/A          N/A         \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "SUMMARY STATISTICS\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "SMALL - Average:                         Accuracy: 89.09%  |  Coverage: 58.58%  |  Total Abstains: 338\n",
      "\n",
      "====================================================================================================================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "====================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, Optional\n",
    "import re\n",
    "\n",
    "def calculate_metrics(df: pd.DataFrame) -> Tuple[float, float, int, int, int]:\n",
    "    \"\"\"\n",
    "    Calculate accuracy (excluding abstains), coverage, and abstain count.\n",
    "    \n",
    "    Returns:\n",
    "        accuracy: float (accuracy excluding abstains)\n",
    "        coverage: float (percentage of non-abstain predictions)\n",
    "        correct: int (number of correct predictions)\n",
    "        total_non_abstain: int (total non-abstain predictions)\n",
    "        abstains: int (number of abstains)\n",
    "    \"\"\"\n",
    "    # Normalize labels to lowercase for comparison\n",
    "    df = df.copy()\n",
    "    df['llm_label_lower'] = df['llm_label'].str.lower().str.strip()\n",
    "    df['gold_label_lower'] = df['gold_label'].str.lower().str.strip()\n",
    "    \n",
    "    # Count abstains\n",
    "    abstains = (df['llm_label_lower'] == 'abstain').sum()\n",
    "    \n",
    "    # Filter out abstains\n",
    "    non_abstain = df[df['llm_label_lower'] != 'abstain']\n",
    "    \n",
    "    # Calculate metrics\n",
    "    total_rows = len(df)\n",
    "    total_non_abstain = len(non_abstain)\n",
    "    \n",
    "    if total_non_abstain > 0:\n",
    "        correct = (non_abstain['llm_label_lower'] == non_abstain['gold_label_lower']).sum()\n",
    "        accuracy = correct / total_non_abstain\n",
    "    else:\n",
    "        correct = 0\n",
    "        accuracy = 0.0\n",
    "    \n",
    "    # Coverage: percentage of non-abstain predictions\n",
    "    coverage = (total_non_abstain / total_rows * 100) if total_rows > 0 else 0.0\n",
    "    \n",
    "    return accuracy, coverage, correct, total_non_abstain, abstains\n",
    "\n",
    "def parse_configuration(filename: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Parse the filename to extract configuration details.\n",
    "    \n",
    "    Returns dict with:\n",
    "        - prompts: 'Few-shot' or 'Zero-shot'\n",
    "        - pipeline: 'Baseline', 'EM-RAG', or 'EM-KGRAG'\n",
    "        - evidence_format: '-', 'Text', 'Python-code', or 'JSON'\n",
    "        - hop_type: 'One-hop' or 'Multi-hop'\n",
    "        - top_k: 'k=1' or 'k=3' (extracted from filename)\n",
    "        - dataset: 'green_claim' or 'emerald_data'\n",
    "        - config_key: unique key for matching (prompts_pipeline_evidence_hop_topk)\n",
    "    \"\"\"\n",
    "    filename_lower = filename.lower()\n",
    "    \n",
    "    # Extract dataset type\n",
    "    if filename_lower.startswith('green_claim_'):\n",
    "        dataset = 'green_claim'\n",
    "    elif filename_lower.startswith('emerald_data_'):\n",
    "        dataset = 'emerald_data'\n",
    "    else:\n",
    "        dataset = 'unknown'\n",
    "    \n",
    "    # Extract prompts\n",
    "    if 'few' in filename_lower:\n",
    "        prompts = 'Few-shot'\n",
    "    elif 'zero' in filename_lower:\n",
    "        prompts = 'Zero-shot'\n",
    "    else:\n",
    "        prompts = 'Unknown'\n",
    "    \n",
    "    # Extract pipeline\n",
    "    if 'baseline' in filename_lower:\n",
    "        pipeline = 'Baseline'\n",
    "    elif 'rag' in filename_lower:\n",
    "        pipeline = 'EM-RAG'\n",
    "    else:\n",
    "        pipeline = 'EM-KGRAG'\n",
    "    \n",
    "    # Extract evidence format\n",
    "    if 'baseline' in filename_lower:\n",
    "        evidence_format = '-'\n",
    "    elif 'rag' in filename_lower:\n",
    "        evidence_format = 'Text'\n",
    "    elif 'python' in filename_lower:\n",
    "        evidence_format = 'Python-code'\n",
    "    else:\n",
    "        evidence_format = 'JSON'\n",
    "    \n",
    "    # Extract hop type\n",
    "    if 'one_hop' in filename_lower:\n",
    "        hop_type = 'One-hop'\n",
    "    elif 'multi_hop' in filename_lower:\n",
    "        hop_type = 'Multi-hop'\n",
    "    else:\n",
    "        hop_type = 'Unknown'\n",
    "    \n",
    "    # Extract top-k value (look for patterns like \"_1_\", \"_3_\", \"hop_1\", \"hop_3\")\n",
    "    top_k = 'Unknown'\n",
    "    # Try to find the k value after \"hop_\"\n",
    "    match = re.search(r'hop_(\\d+)', filename_lower)\n",
    "    if match:\n",
    "        k_value = match.group(1)\n",
    "        top_k = f'k={k_value}'\n",
    "    \n",
    "    # Create a configuration key for matching\n",
    "    config_key = f\"{prompts}_{pipeline}_{evidence_format}_{hop_type}_{top_k}\"\n",
    "    \n",
    "    return {\n",
    "        'prompts': prompts,\n",
    "        'pipeline': pipeline,\n",
    "        'evidence_format': evidence_format,\n",
    "        'hop_type': hop_type,\n",
    "        'top_k': top_k,\n",
    "        'dataset': dataset,\n",
    "        'config_key': config_key\n",
    "    }\n",
    "\n",
    "def process_dataset(file_path: str) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Process a single dataset and return its metrics and configuration.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        accuracy, coverage, correct, total_non_abstain, abstains = calculate_metrics(df)\n",
    "        \n",
    "        config = parse_configuration(Path(file_path).name)\n",
    "        \n",
    "        return {\n",
    "            'file': file_path,\n",
    "            'accuracy': accuracy,\n",
    "            'coverage': coverage,\n",
    "            'abstains': abstains,\n",
    "            'total_rows': len(df),\n",
    "            **config,\n",
    "            'success': True\n",
    "        }\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: {file_path} not found\")\n",
    "        return None\n",
    "    except KeyError as e:\n",
    "        print(f\"Warning: Required column not found in {file_path}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_comparison_table(green_claim_files: list, emerald_data_files: list):\n",
    "    \"\"\"\n",
    "    Create a comparison table showing green_claim and emerald_data datasets side-by-side.\n",
    "    \"\"\"\n",
    "    # Process all files\n",
    "    green_claim_results = {}\n",
    "    emerald_data_results = {}\n",
    "    results_dir = 'results/'\n",
    "    print(\"\\nProcessing files...\")\n",
    "    for file in green_claim_files:\n",
    "        file = results_dir + file\n",
    "        result = process_dataset(file)\n",
    "        if result:\n",
    "            green_claim_results[result['config_key']] = result\n",
    "    \n",
    "    for file in emerald_data_files:\n",
    "        file = results_dir + file\n",
    "        result = process_dataset(file)\n",
    "        if result:\n",
    "            emerald_data_results[result['config_key']] = result\n",
    "    \n",
    "    # Get all unique configurations\n",
    "    all_configs = sorted(set(green_claim_results.keys()) | set(emerald_data_results.keys()))\n",
    "    \n",
    "    if not all_configs:\n",
    "        print(\"No configurations found.\")\n",
    "        return\n",
    "    \n",
    "    # Print header\n",
    "    print(f\"\\n{'='*180}\")\n",
    "    print(\"SIDE-BY-SIDE COMPARISON: green_claim vs emerald_data DATASETS\")\n",
    "    print(f\"{'='*180}\")\n",
    "    \n",
    "    # Column headers\n",
    "    print(f\"\\n{'Prompts':<12s} {'Pipeline':<12s} {'Hop Type':<12s} {'Top-K':<8s} {'Evidence':<15s} \"\n",
    "          f\"{'Acc_green_claim':<12s} {'Cov_green_claim':<12s} {'Abs_green_claim':<12s} \"\n",
    "          f\"{'Acc_emerald_data':<12s} {'Cov_emerald_data':<12s} {'Abs_emerald_data':<12s}\")\n",
    "    print(f\"{'-'*180}\")\n",
    "    \n",
    "    # Print each configuration\n",
    "    for config_key in all_configs:\n",
    "        green_claim = green_claim_results.get(config_key)\n",
    "        emerald_data = emerald_data_results.get(config_key)\n",
    "        \n",
    "        # Get configuration from whichever exists\n",
    "        config = green_claim if green_claim else emerald_data\n",
    "        if not config:\n",
    "            continue\n",
    "        \n",
    "        prompts = config['prompts']\n",
    "        pipeline = config['pipeline']\n",
    "        hop_type = config['hop_type']\n",
    "        top_k = config['top_k']\n",
    "        evidence = config['evidence_format']\n",
    "        \n",
    "        # green_claim dataset metrics\n",
    "        if green_claim:\n",
    "            acc_green_claim = f\"{green_claim['accuracy']*100:.2f}%\"\n",
    "            cov_green_claim = f\"{green_claim['coverage']:.2f}%\"\n",
    "            abs_green_claim = f\"{green_claim['abstains']}\"\n",
    "        else:\n",
    "            acc_green_claim = \"N/A\"\n",
    "            cov_green_claim = \"N/A\"\n",
    "            abs_green_claim = \"N/A\"\n",
    "        \n",
    "        # emerald_data dataset metrics\n",
    "        if emerald_data:\n",
    "            acc_emerald_data = f\"{emerald_data['accuracy']*100:.2f}%\"\n",
    "            cov_emerald_data = f\"{emerald_data['coverage']:.2f}%\"\n",
    "            abs_emerald_data = f\"{emerald_data['abstains']}\"\n",
    "        else:\n",
    "            acc_emerald_data = \"N/A\"\n",
    "            cov_emerald_data = \"N/A\"\n",
    "            abs_emerald_data = \"N/A\"\n",
    "        \n",
    "        print(f\"{prompts:<12s} {pipeline:<12s} {hop_type:<12s} {top_k:<8s} {evidence:<15s} \"\n",
    "              f\"{acc_green_claim:<12s} {cov_green_claim:<12s} {abs_green_claim:<12s} \"\n",
    "              f\"{acc_emerald_data:<12s} {cov_emerald_data:<12s} {abs_emerald_data:<12s}\")\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\n{'-'*180}\")\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(f\"{'-'*180}\")\n",
    "    \n",
    "    # Calculate averages for green_claim\n",
    "    if green_claim_results:\n",
    "        avg_acc_green_claim = sum(r['accuracy'] for r in green_claim_results.values()) / len(green_claim_results)\n",
    "        avg_cov_green_claim = sum(r['coverage'] for r in green_claim_results.values()) / len(green_claim_results)\n",
    "        total_abs_green_claim = sum(r['abstains'] for r in green_claim_results.values())\n",
    "        \n",
    "        print(f\"{'green_claim - Average:':<40s} Accuracy: {avg_acc_green_claim*100:.2f}%  |  Coverage: {avg_cov_green_claim:.2f}%  |  Total Abstains: {total_abs_green_claim}\")\n",
    "    \n",
    "    # Calculate averages for emerald_data\n",
    "    if emerald_data_results:\n",
    "        avg_acc_emerald_data = sum(r['accuracy'] for r in emerald_data_results.values()) / len(emerald_data_results)\n",
    "        avg_cov_emerald_data = sum(r['coverage'] for r in emerald_data_results.values()) / len(emerald_data_results)\n",
    "        total_abs_emerald_data = sum(r['abstains'] for r in emerald_data_results.values())\n",
    "        \n",
    "        print(f\"{'emerald_data - Average:':<40s} Accuracy: {avg_acc_emerald_data*100:.2f}%  |  Coverage: {avg_cov_emerald_data:.2f}%  |  Total Abstains: {total_abs_emerald_data}\")\n",
    "\n",
    "def main():\n",
    "    emerald_data_var=[\n",
    "    \"emerald_data_few_baseline.csv\",\n",
    "    \"emerald_data_few_one_hop_3.csv\",\n",
    "    \"emerald_data_few_rag.csv\",\n",
    "    \"emerald_data_zero_baseline.csv\",\n",
    "    \"emerald_data_zero_one_hop_3.csv\",\n",
    "    \"emerald_data_zero_rag.csv\",\n",
    "    ]\n",
    "    green_claim_var=[\n",
    "    \"green_claim_few_baseline.csv\",\n",
    "    \"green_claim_few_one_hop_3.csv\",\n",
    "    \"green_claim_few_rag.csv\",\n",
    "    \"green_claim_zero_baseline.csv\",\n",
    "    \"green_claim_zero_one_hop_3.csv\",\n",
    "    \"green_claim_zero_rag.csv\",\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*180)\n",
    "    print(\"ACCURACY ANALYSIS: GREEN CLAIMS vs EMERALD DATA DATASETS\")\n",
    "    print(\"=\"*180)\n",
    "    print(\"\\nConfiguration Legend:\")\n",
    "    print(\"  - Prompts: Few-shot or Zero-shot\")\n",
    "    print(\"  - Pipeline: Baseline | EM-RAG | EM-KGRAG\")\n",
    "    print(\"  - Hop Type: One-hop | Multi-hop\")\n",
    "    print(\"  - Top-K: k=1 | k=3 (number of evidence paths retrieved)\")\n",
    "    print(\"  - Evidence Format: - (baseline) | Text (RAG) | Python-code | JSON\")\n",
    "    print(\"  - Accuracy: Excluding abstains\")\n",
    "    print(\"  - Coverage: Percentage of non-abstain predictions\")\n",
    "    \n",
    "    create_comparison_table(green_claim_var, emerald_data_var)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*180)\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(\"=\"*180)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2660d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
